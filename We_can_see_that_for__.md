From these diagnostic plots we can evaluate how well each simulation is reproducing the real dataset and in which ways it differs. For example, Figure \ref{fig:comparison} shows that for this dataset the Lun 2 simulations produce much more highly variable genes and fails to capture the mean-variance relationship while the Lun simulation produces smaller library sizes and the scDD simulation has too few zeros in both genes and cells. While this view allows us to visually inspect how simulations compare on a single dataset it does not give a clear indication of which simulation performs best on each metric or allow us to compare simulations across datasets. In order to do this we calculated a ranked MAD for each metric by ordering both the simulated and real values then taking the difference between them. For example to get a MAD for the means the mean expression for both the real data and the simulations were sorted, the real values were then subtracted from the simulated values and the median of the absolute differences taken as the final statistic. We then ranked the MADs for each metric to compare the simulations. Figure \ref{fig:ranks} summarises the results as a heatmap.