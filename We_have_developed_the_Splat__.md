We have developed the Splat simulation to capture many of the technical effects seen in real scRNA-Seq data, including high expression outliers, differing sequencing depths between cells, trended gene-wise dispersion, as well as zero-inflation, using parametric distributions with hyper-parameters estimated from real data (Figure 1). The Splat simulation model is based on the gamma-Poisson hierarchical model where the mean expression level for each gene is simulated from a gamma distribution and the count for each cell is subsequently sampled from a Poisson distribution, with modifications to include expression outliers and to enforce a mean-variance trend. 

We initially sample gene means from a Gamma distribution with shape \(\alpha\) and rate \(\beta\) parameters estimated from the library size normalised counts. While the gamma distribution is a good fit for gene means it does not always capture extreme expression levels. To counter this we allow the user to specify a probability (\(\pi^{O}\)) that a gene is a high expression outlier. We then add these outliers to the simulation by replacing the previously simulated mean with the median mean expression level multiplied by an inflation factor.The inflation factor is sampled from a log-normal distribution with location \(\mu^{O}\) and scale \(\sigma^{O}\).

The library size (total number of counts) varies within an scRNA-seq experiment and can be very different between experiments depending on the sequencing depth. We model library size using a log-normal distribution (with location \(\mu^{L}\) and scale \(\sigma^{L}\)) and use the simulated library sizes (\(L_j\)) to proportionally adjust the gene means for each cell. This allows us to alter the number of counts per cell independently of the underlying gene expression levels. 

It is well known that there is a strong mean-variance trend in RNA-Seq data, where lowly expressed genes are more variable and highly expressed genes are more consistent. In the Splat simulation we enforce this trend by simulating the biological coefficient of variation (BCV) for each gene from a scaled inverse chi-square distribution, where the scaling factor is a function of the gene mean. After simulating the BCV values we generate a new set of means (\(\lambda_{i,j}\)) from a Gamma distribution with shape and rate parameters dependent on the simulated BCVs and previous gene means. We then generate a matrix of counts by sampling from a Poisson distribution, with lambda equal to \(\lambda_{i,j}\). This process is similar to that used by Law et al. in their simulation of RNA-seq data \cite{Law_2014}.

As discussed previously one of the key features of scRNA-seq data is the high proportion of zeros, one cause of which is technical dropout. We use the relationship between the mean expression of a gene and the proportion of zeros in that gene to model this process using a logistic function to produce a probability that a count should be zero. These probabilities are then used to randomly replace the simulated counts with zeros using a Bernoulli distribution. As with the other parts of the Splat simulation this step is easily controlled by the user and can be turned off when it is not desirable or appropriate. The final result is a matrix of observed counts \(Y_{i,j}\) where the rows are genes and the columns are cells. The full set of input parameters are shown in Table \ref{tab:params} and the intermediate values and the equations used to produce them in Table \ref{tab:intermediate}.